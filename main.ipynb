{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning Azure OpenAI\n",
    "What do you do when RAG doesn't work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare your training and validation data\n",
    "Your training data and validation data sets consist of input and output examples for how you would like the model to perform.\n",
    "\n",
    "The more training examples you have, the better. Fine tuning jobs will not proceed without at least 10 training examples, but such a small number is not enough to noticeably influence model responses. It is best practice to provide hundreds, if not thousands, of training examples to be successful.\n",
    "\n",
    "In general, doubling the dataset size can lead to a linear increase in model quality. But keep in mind, low quality examples can negatively impact performance. If you train the model on a large amount of internal data, without first pruning the dataset for only the highest quality examples you could end up with a model that performs much worse than expected.\n",
    "\n",
    "The training and validation data you use must be formatted as a JSON Lines (JSONL) document. For gpt-35-turbo-0613 the fine-tuning dataset must be formatted in the conversational format that is used by the Chat completions API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example file format\n",
    "\n",
    "See [example.jsonl](data/example.jsonl) for JSONL example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-turn chat file format\n",
    "\n",
    "Multiple turns of a conversation in a single line of your jsonl training file is also supported. To skip fine-tuning on specific assistant messages add the optional weight key value pair. Currently weight can be set to 0 or 1.\n",
    "\n",
    "See [multi-turn-example.jsonl](data/multi-turn-example.jsonl) for JSONL example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat completions with vision\n",
    "\n",
    "See [vision-example.jsonl](data/vision-example.jsonl) for JSONL example.\n",
    "\n",
    "In addition to the JSONL format, training and validation data files must be encoded in UTF-8 and include a byte-order mark (BOM). The file must be less than 512 MB in size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload your training data\n",
    "\n",
    "There are two ways to upload training data:\n",
    "\n",
    "* [From a local file](https://learn.microsoft.com/en-us/rest/api/azureopenai/files/upload?view=rest-azureopenai-2024-10-21&tabs=HTTP)\n",
    "* [Import from an Azure Blob store or other web location](https://learn.microsoft.com/en-us/rest/api/azureopenai/files/import?view=rest-azureopenai-2024-10-21&tabs=HTTP)\n",
    "\n",
    "For large data files, it's recommended that you import from an Azure Blob store. Large files can become unstable when uploaded through multipart forms because the requests are atomic and can't be retried or resumed. \n",
    "\n",
    "The following Python example uploads local training and validation files by using the Python SDK, and retrieves the returned file IDs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=os.getenv(\"API_VERSION\")  # This API version or later is required to access seed/events/checkpoint capabilities\n",
    ")\n",
    "\n",
    "training_file_name = 'training_set.jsonl'\n",
    "validation_file_name = 'validation_set.jsonl'\n",
    "\n",
    "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
    "\n",
    "training_response = client.files.create(\n",
    "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response.id\n",
    "\n",
    "validation_response = client.files.create(\n",
    "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a customised model\n",
    "After you upload your training and validation files, you're ready to start the fine-tuning job.\n",
    "\n",
    "The following Python code shows an example of how to create a new fine-tune job with the Python SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=os.getenv(\"MODEL_NAME\"), # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters. \n",
    "    seed = 105  # seed parameter controls reproducibility of the fine-tuning job. If no seed is specified one will be generated automatically.\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.id)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass additional optional parameters like hyperparameters to take greater control of the fine-tuning process. For initial training we recommend using the automatic defaults that are present without specifying these parameters.\n",
    "\n",
    "The current supported hyperparameters for fine-tuning are:\n",
    "\n",
    "| Name                  | Type     | Description |\n",
    "|-----------------------|---------|-------------|\n",
    "| batch_size           | integer | The batch size to use for training. The batch size is the number of training examples used to train a single forward and backward pass. In general, we've found that larger batch sizes tend to work better for larger datasets. The default value as well as the maximum value for this property are specific to a base model. A larger batch size means that model parameters are updated less frequently, but with lower variance. |\n",
    "| learning_rate_multiplier | number  | The learning rate multiplier to use for training. The fine-tuning learning rate is the original learning rate used for pre-training multiplied by this value. Larger learning rates tend to perform better with larger batch sizes. We recommend experimenting with values in the range 0.02 to 0.2 to see what produces the best results. A smaller learning rate can be useful to avoid overfitting. |\n",
    "| n_epochs             | integer | The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset. |\n",
    "| seed                 | integer | The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases. If a seed isn't specified, one will be generated for you. |\n",
    "\n",
    "To set custom hyperparameters with the 1.x version of the OpenAI Python API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=os.getenv(\"API_VERSION\")  # \"2024-02-01\" or later is required\n",
    ")\n",
    "\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-abc123\", \n",
    "  model=os.getenv(\"MODEL_NAME\"),\n",
    "  hyperparameters={\n",
    "    \"n_epochs\":2\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check fine-tuning job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List fine-tuning events\n",
    "To examine the individual fine-tuning events that were generated during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints\n",
    "\n",
    "When each training epoch completes a checkpoint is generated. A checkpoint is a fully functional version of a model which can both be deployed and used as the target model for subsequent fine-tuning jobs. Checkpoints can be particularly useful, as they can provide a snapshot of your model prior to overfitting having occurred. When a fine-tuning job completes you will have the three most recent versions of the model available to deploy. The final epoch will be represented by your fine-tuned model, the previous two epochs will be available as checkpoints.\n",
    "\n",
    "You can run the list checkpoints command to retrieve the list of checkpoints associated with an individual fine-tuning job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a fine-tuned model\n",
    "When the fine-tuning job succeeds, the value of the `fine_tuned_model` variable in the response body is set to the name of your customized model. Your model is now also available for discovery from the list Models API. However, you can't issue completion calls to your customized model until your customized model is deployed. You must deploy your customized model to make it available for use with completion calls.\n",
    "\n",
    "After you deploy a customized model, if at any time the deployment remains inactive for greater than fifteen (15) days, the deployment is deleted. The deployment of a customized model is inactive if the model was deployed more than fifteen (15) days ago and no completions or chat completions calls were made to it during a continuous 15-day period.\n",
    "\n",
    "The deletion of an inactive deployment doesn't delete or affect the underlying customized model, and the customized model can be redeployed at any time. As described in Azure OpenAI Service pricing, each customized (fine-tuned) model that's deployed incurs an hourly hosting cost regardless of whether completions or chat completions calls are being made to the model. To learn more about planning and managing costs with Azure OpenAI, refer to the guidance in Plan to manage costs for Azure OpenAI Service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use Azure AI Foundry or the Azure CLI to deploy your customized model.\n",
    "\n",
    "Note: Only one deployment is permitted for a customized model. An error occurs if you select an already-deployed customized model.\n",
    "\n",
    "Unlike the previous SDK commands, deployment must be done using the control plane API which requires separate authorization, a different API path, and a different API version.\n",
    "\n",
    "| Variable               | Definition |\n",
    "|------------------------|------------|\n",
    "| token                  | There are multiple ways to generate an authorization token. The easiest method for initial testing is to launch the Cloud Shell from the Azure portal. Then run `az account get-access-token`. You can use this token as your temporary authorization token for API testing. We recommend storing this in a new environment variable. |\n",
    "| subscription           | The subscription ID for the associated Azure OpenAI resource. |\n",
    "| resource_group         | The resource group name for your Azure OpenAI resource. |\n",
    "| resource_name          | The Azure OpenAI resource name. |\n",
    "| model_deployment_name  | The custom name for your new fine-tuned model deployment. This is the name that will be referenced in your code when making chat completion calls. |\n",
    "| fine_tuned_model       | Retrieve this value from your fine-tuning job results in the previous step. It will look like `gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83`. You will need to add that value to the deploy_data json. Alternatively, you can also deploy a checkpoint, by passing the checkpoint ID which will appear in the format `ftchkpt-e559c011ecc04fc68eaa339d8227d02d`. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "token= os.getenv(\"<TOKEN>\") \n",
    "subscription = \"<YOUR_SUBSCRIPTION_ID>\"  \n",
    "resource_group = \"<YOUR_RESOURCE_GROUP_NAME>\"\n",
    "resource_name = \"<YOUR_AZURE_OPENAI_RESOURCE_NAME>\"\n",
    "model_deployment_name =\"gpt-35-turbo-ft\" # custom deployment name that you will use to reference the model when making inference calls.\n",
    "\n",
    "deploy_params = {'api-version': \"2023-05-01\"} \n",
    "deploy_headers = {'Authorization': 'Bearer {}'.format(token), 'Content-Type': 'application/json'}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 1}, \n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": <\"fine_tuned_model\">, #retrieve this value from the previous call, it will look like gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83\n",
    "            \"version\": \"1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "request_url = f'https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}'\n",
    "\n",
    "print('Creating a new deployment...')\n",
    "\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross region deployment\n",
    "Fine-tuning supports deploying a fine-tuned model to a different region than where the model was originally fine-tuned. You can also deploy to a different subscription/region.\n",
    "\n",
    "The only limitations are that the new region must also support fine-tuning and when deploying cross subscription the account generating the authorization token for the deployment must have access to both the source and destination subscriptions.\n",
    "\n",
    "Below is an example of deploying a model that was fine-tuned in one subscription/region to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "token= os.getenv(\"<TOKEN>\") \n",
    "\n",
    "subscription = \"<DESTINATION_SUBSCRIPTION_ID>\"  \n",
    "resource_group = \"<DESTINATION_RESOURCE_GROUP_NAME>\"\n",
    "resource_name = \"<DESTINATION_AZURE_OPENAI_RESOURCE_NAME>\"\n",
    "\n",
    "source_subscription = \"<SOURCE_SUBSCRIPTION_ID>\"\n",
    "source_resource_group = \"<SOURCE_RESOURCE_GROUP>\"\n",
    "source_resource = \"<SOURCE_RESOURCE>\"\n",
    "\n",
    "\n",
    "source = f'/subscriptions/{source_subscription}/resourceGroups/{source_resource_group}/providers/Microsoft.CognitiveServices/accounts/{source_resource}'\n",
    "\n",
    "model_deployment_name =\"gpt-35-turbo-ft\" # custom deployment name that you will use to reference the model when making inference calls.\n",
    "\n",
    "deploy_params = {'api-version': \"2023-05-01\"} \n",
    "deploy_headers = {'Authorization': 'Bearer {}'.format(token), 'Content-Type': 'application/json'}\n",
    "\n",
    "\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 1}, \n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": <\"FINE_TUNED_MODEL_NAME\">, # This value will look like gpt-35-turbo-0613.ft-0ab3f80e4f2242929258fff45b56a9ce \n",
    "            \"version\": \"1\",\n",
    "            \"source\": source\n",
    "        }\n",
    "    }\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "request_url = f'https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}'\n",
    "\n",
    "print('Creating a new deployment...')\n",
    "\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deploy between the same subscription, but different regions you would just have subscription and resource groups be identical for both source and destination variables and only the source and destination resource names would need to be unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross tenant deployment\n",
    "The account used to generate access tokens with `az account get-access-token --tenant` should have Cognitive Services OpenAI Contributor permissions to both the source and destination Azure OpenAI resources. You will need to generate two different tokens, one for the source tenant and one for the destination tenant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "subscription = \"DESTINATION-SUBSCRIPTION-ID\"\n",
    "resource_group = \"DESTINATION-RESOURCE-GROUP\"\n",
    "resource_name = \"DESTINATION-AZURE-OPENAI-RESOURCE-NAME\"\n",
    "model_deployment_name = \"DESTINATION-MODEL-DEPLOYMENT-NAME\"\n",
    "fine_tuned_model = \"gpt-4o-mini-2024-07-18.ft-f8838e7c6d4a4cbe882a002815758510\" #source fine-tuned model id example id provided\n",
    "source_subscription_id = \"SOURCE-SUBSCRIPTION-ID\"\n",
    "source_resource_group = \"SOURCE-RESOURCE-GROUP\" \n",
    "source_account = \"SOURCE-AZURE-OPENAI-RESOURCE-NAME\"\n",
    "\n",
    "dest_token = \"DESTINATION-ACCESS-TOKEN\" # az account get-access-token --tenant DESTINATION-TENANT-ID\n",
    "source_token = \"SOURCE-ACCESS-TOKEN\"  # az account get-access-token --tenant SOURCE-TENANT-ID\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {dest_token}\", \n",
    "    \"x-ms-authorization-auxiliary\": f\"Bearer {source_token}\", \n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "url = f\"https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}?api-version=2024-10-01\"\n",
    "\n",
    "payload = {\n",
    "    \"sku\": {\n",
    "        \"name\": \"standard\",\n",
    "        \"capacity\": 1\n",
    "    },\n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": fine_tuned_model,\n",
    "            \"version\": \"1\",\n",
    "            \"sourceAccount\": f\"/subscriptions/{source_subscription_id}/resourceGroups/{source_resource_group}/providers/Microsoft.CognitiveServices/accounts/{source_account}\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.put(url, headers=headers, json=payload)\n",
    "\n",
    "# Check response\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Response: {response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a deployed customized model\n",
    "After your custom model deploys, you can use it like any other deployed model. You can use the Chat Playground in Azure AI Foundry to experiment with your new deployment. You can continue to use the same parameters with your custom model, such as temperature and max_tokens, as you can with other deployed models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo-ft\", # model = \"Custom deployment name you chose for your fine-tuning model\"\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Does Azure OpenAI support customer managed keys?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Yes, customer managed keys are supported by Azure OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Do other Azure AI services support this too?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze your customized model\n",
    "Azure OpenAI attaches a result file named results.csv to each fine-tune job after it completes. You can use the result file to analyze the training and validation performance of your customized model. The file ID for the result file is listed for each customized model, and you can use the Python SDK to retrieve the file ID and download the result file for analysis.\n",
    "\n",
    "The following Python example retrieves the file ID of the first result file attached to the fine-tuning job for your customized model, and then uses the Python SDK to download the file to your working directory for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the file ID of the first result file from the fine-tuning job\n",
    "# for the customized model.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "if response.status == 'succeeded':\n",
    "    result_file_id = response.result_files[0]\n",
    "\n",
    "retrieve = client.files.retrieve(result_file_id)\n",
    "\n",
    "# Download the result file.\n",
    "print(f'Downloading result file: {result_file_id}')\n",
    "\n",
    "with open(retrieve.filename, \"wb\") as file:\n",
    "    result = client.files.content(result_file_id).read()\n",
    "    file.write(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result file is a CSV file that contains a header row and a row for each training step performed by the fine-tuning job. The result file contains the following columns:\n",
    "\n",
    "| Column Name                         | Description |\n",
    "|-------------------------------------|-------------|\n",
    "| step                                | The number of the training step. A training step represents a single pass, forward and backward, on a batch of training data. |\n",
    "| train_loss                          | The loss for the training batch. |\n",
    "| train_mean_token_accuracy          | The percentage of tokens in the training batch correctly predicted by the model. For example, if the batch size is set to 3 and your data contains completions `[[1, 2], [0, 5], [4, 2]]`, this value is set to 0.83 (5 of 6) if the model predicted `[[1, 1], [0, 5], [4, 2]]`. |\n",
    "| valid_loss                          | The loss for the validation batch. |\n",
    "| validation_mean_token_accuracy     | The percentage of tokens in the validation batch correctly predicted by the model. For example, if the batch size is set to 3 and your data contains completions `[[1, 2], [0, 5], [4, 2]]`, this value is set to 0.83 (5 of 6) if the model predicted `[[1, 1], [0, 5], [4, 2]]`. |\n",
    "| full_valid_loss                     | The validation loss calculated at the end of each epoch. When training goes well, loss should decrease. |\n",
    "| full_valid_mean_token_accuracy     | The valid mean token accuracy calculated at the end of each epoch. When training is going well, token accuracy should increase. |\n",
    "\n",
    "Look for your loss to decrease over time, and your accuracy to increase. If you see a divergence between your training and validation data that can indicate that you are overfitting. Try training with fewer epochs, or a smaller learning rate multiplier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
